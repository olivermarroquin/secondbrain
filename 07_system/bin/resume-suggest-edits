#!/Users/olivermarroquin/secondbrain/07_system/venvs/docgen/bin/python
import argparse, json, os, re
from pathlib import Path
from datetime import datetime, timezone

def die(msg: str, code=1):
    print(f"ERROR: {msg}")
    raise SystemExit(code)

def load_json(p: Path):
    try:
        return json.loads(p.read_text())
    except Exception as e:
        die(f"invalid JSON: {p} ({e})")

def norm(s: str) -> str:
    s = (s or "").lower()
    s = s.replace("\u2019", "'")
    s = re.sub(r"\s+", " ", s)
    return s.strip()

def has(text: str, kw: str) -> bool:
    kw = (kw or "").strip().lower()
    return bool(kw) and kw in text

def score(sig: dict, text: str) -> tuple[int, list[str], list[str], list[str]]:
    pref = [k for k in sig.get("preferred_keywords", []) if isinstance(k, str)]
    neut = [k for k in sig.get("neutral_keywords", []) if isinstance(k, str)]
    anti = [k for k in sig.get("anti_signals", []) if isinstance(k, str)]

    hits_pref = [k for k in pref if has(text, k)]
    hits_neut = [k for k in neut if has(text, k)]
    hits_anti = [k for k in anti if has(text, k)]

    sc = 0
    sc += 10 * len(hits_pref)
    sc += 2 * len(hits_neut)
    sc -= 12 * len(hits_anti)

    ps = sig.get("primary_stack", {}) or {}
    lang = (ps.get("language") or "").lower()
    tool = (ps.get("automation_tool") or "").lower()
    if lang and has(text, lang): sc += 6
    if tool and has(text, tool): sc += 8

    # role bias: Cypress → TS/JS modern web automation
    if has(text, "cypress") and str(sig.get("template_id","")) == "04":
        sc += 10

    return sc, hits_pref, hits_neut, hits_anti

def select_template(family_root: Path, jd_text_norm: str, requested: str):
    rows = []
    for sig_p in family_root.rglob("signals.json"):
        sig = load_json(sig_p)
        sc, hp, hn, ha = score(sig, jd_text_norm)
        rows.append({
            "score": sc,
            "sig": sig,
            "path": sig_p.parent,
            "hits_pref": hp,
            "hits_neut": hn,
            "hits_anti": ha,
        })
    if not rows:
        die(f"no signals.json found under: {family_root}")

    if requested != "auto":
        req = requested.strip().lower()
        # allow "04", "04_typescript_playwright", "typescript_playwright"
        for r in rows:
            tid = str(r["sig"].get("template_id","")).zfill(2)
            slug = (r["sig"].get("template_slug") or r["path"].name).lower()
            if req == tid or req == slug or req == slug.replace(tid + "_","") or req == r["path"].name.lower():
                return r, sorted(rows, key=lambda x: x["score"], reverse=True)
        die(f"requested template not found: {requested}")

    rows.sort(key=lambda r: r["score"], reverse=True)
    return rows[0], rows

# ---- semantic guardrails (deterministic) ----
def term_category(term: str) -> str:
    t = (term or "").lower()
    if any(x in t for x in ["performance/load", "performance/load/stress", "load/stress", "load testing", "stress testing"]):
        return "PERF"
    if any(x in t for x in ["ui/ux", "ux"]):
        return "UX"
    if "sql" in t:
        return "SQL"
    return "GEN"

def line_has_perf_cues(line: str) -> bool:
    l = (line or "").lower()
    return any(x in l for x in ["performance", "load", "stress", "jmeter", "gatling", "k6"])

def line_has_sql_cues(line: str) -> bool:
    l = (line or "").lower()
    return any(x in l for x in ["sql", "database", "jdbc", "query"])

def line_has_ux_cues(line: str) -> bool:
    l = (line or "").lower()
    return any(x in l for x in ["ui", "ux", "user experience", "front end", "frontend", "ui/ux"])

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--app", required=True)
    ap.add_argument("--template", default="auto", help="auto|template_id|template_slug")
    ap.add_argument("--diff", action="store_true", help="Show BEFORE/AFTER diffs (recommended)")
    ap.add_argument("--family", default="qa_automation_engineer")
    ap.add_argument("--no-write", action="store_true", help="Do not write edit-proposals.json")
    args = ap.parse_args()

    app = Path(args.app).expanduser()
    if not app.is_dir():
        die(f"app dir missing: {app}")

    jm_p = app / "tracking" / "job-meta.json"
    jd_p = app / "jd" / "jd-raw.txt"
    if not jm_p.exists(): die(f"missing: {jm_p}")
    if not jd_p.exists(): die(f"missing: {jd_p}")
    if jd_p.stat().st_size == 0: die(f"jd-raw.txt empty: {jd_p}")

    jm = load_json(jm_p)
    jd_raw = jd_p.read_text(errors="ignore")
    jd_norm = norm(jd_raw)

    family_root = Path.home() / "secondbrain/03_assets/templates/resumes" / args.family
    if not family_root.is_dir():
        die(f"template family root missing: {family_root}")

    best, _rows = select_template(family_root, jd_norm, args.template)
    sig = best["sig"]
    template_id_raw = str(sig.get("template_id","??"))
    template_id = template_id_raw.zfill(2) if template_id_raw.isdigit() else template_id_raw
    template_slug = sig.get("template_slug", best["path"].name)
    template_path = best["path"]
    docx_path = template_path / "resume-master.docx"

    # Import internal helpers (repo-relative, deterministic)
    scripts_dir = Path.home() / "secondbrain/01_projects/resume-factory/scripts"
    if not scripts_dir.is_dir():
        die(f"missing scripts dir: {scripts_dir}")
    import sys
    sys.path.insert(0, str(scripts_dir))

    from rf_docx_extract import read_docx_lines, locate_sections, format_numbered_blocks_for_prompt
    from rf_openai_client import propose_edits_openai
    from rf_proposal_schema import validate_proposals
    from rf_print_diff import print_diff
    from rf_jd_terms import extract_jd_terms, rationale_mentions_term

    # Extract resume text blocks deterministically
    lines = read_docx_lines(docx_path)
    header, summary, skills, exp = locate_sections(lines)
    resume_blocks_numbered, line_index = format_numbered_blocks_for_prompt(header, summary, skills, exp, max_exp_lines=90)
    resume_all_text = "\n".join([v["text"] for v in line_index.values()]).lower()

    # Provider call (AI proposes only)
    if not os.environ.get("OPENAI_API_KEY"):
        die("missing OPENAI_API_KEY (export it in your shell)")

    jd_terms = extract_jd_terms(jd_raw)
    missing_terms = [t for t in jd_terms if t and t.lower() not in resume_all_text]

    proposals = propose_edits_openai(
        jd_raw=jd_raw,
        resume_blocks_numbered=resume_blocks_numbered,
        signals=sig,
        jd_terms=missing_terms,
        model=os.environ.get("RF_OPENAI_MODEL", None),
        max_proposals=int(os.environ.get("RF_MAX_PROPOSALS", "12")),
        timeout_s=int(os.environ.get("RF_OPENAI_TIMEOUT_S", "60")),
    )

    # Enforce "before exists verbatim" + section scoping deterministically
    # (Model is instructed, but we verify and drop violations.)
    summary_text = "\n".join(summary)
    skills_text = "\n".join(skills)
    exp_text = "\n".join(exp)

    filtered = []
    dropped = 0
    dropped_notes = []
    for p in proposals:
        before = (p.get("before") or [""])[0]
        section = (p.get("section") or "").strip().upper()

        def drop(reason: str):
            nonlocal dropped
            dropped += 1
            dropped_notes.append({
                "section": section,
                "reason": reason,
                "before": before,
            })

        if not before or not isinstance(before, str):
            drop("missing_or_nonstring_before")
            continue
        
        before_ref = (p.get("before_ref") or "").strip()
        if not before_ref or before_ref not in line_index:
            drop("missing_or_invalid_before_ref")
            continue

        # Allow fuzzy matching for SUMMARY (long lines often wrap/truncate)
        resume_line_text = line_index.get(before_ref, {}).get("text", "")
        if section == "SUMMARY":
            if before.lower() not in resume_line_text.lower():
                drop("before_text_mismatch_for_before_ref")
                continue
        else:
            if before != resume_line_text:
                drop("before_text_mismatch_for_before_ref")
                continue

        ref_section = line_index[before_ref]["section"]
        if section and section != ref_section:
            drop("section_mismatch_for_before_ref")
            continue
        
        if section == "SUMMARY" and before not in summary_text:
            drop("before_not_in_summary_block")
            continue
        if section == "SKILLS" and before not in skills_text:
            drop("before_not_in_skills_block")
            continue
        if section == "EXPERIENCE" and before not in exp_text:
            drop("before_not_in_experience_block")
            continue

        jd_term = (p.get("jd_term") or "").strip().lower()
        rationale = (p.get("rationale") or "")

        if jd_terms:
            # Must select a term we provided
            if not jd_term or jd_term not in [t.lower() for t in jd_terms]:
                drop("missing_or_invalid_jd_term")
                continue
            # Rationale must explicitly include the chosen term
            if jd_term not in rationale.lower():
                drop("rationale_missing_jd_term")
                continue

        # Missing-term gate: reject proposals for terms already present in resume
        if jd_term and jd_term in resume_all_text:
            drop("jd_term_already_present_in_resume")
            continue

        # ---- semantic guardrails (stop "keyword stuffing" into wrong lines) ----
        cat = term_category(jd_term)
        before_line = line_index.get(before_ref, {}).get("text", "")

        if cat == "PERF":
            # Allow perf/load terms on SQL lines IF backend/system context exists
            if line_has_sql_cues(before_line):
                backend_ok = any(x in before_line.lower() for x in [
                    "backend", "back-end", "system", "pipeline", "integration", "service"
                ])
                if not backend_ok and not line_has_perf_cues(before_line):
                    drop("semantic_mismatch_perf_term_in_sql_line")
                    continue
        
        if cat == "UX":
            # Avoid recruiter-weird phrasing like "UI/UX Selenium infrastructure" unless the line already signals UI/UX
            if "selenium" in before_line.lower() and not line_has_ux_cues(before_line):
                drop("semantic_mismatch_ux_term_in_selenium_line")
                continue       
    
        filtered.append(p)

    # Assign deterministic ids (approve step expects stable ids)
    for i, p in enumerate(filtered, start=1):
        p["id"] = i

    ok, msg = validate_proposals(filtered)
    if not ok:
        die(f"proposal schema failed: {msg}")

    print(f"APP: {app}")
    print(f"JOB: {jm.get('company','?')} | {jm.get('role_title','?')} | date_found={jm.get('date_found','?')}")
    print(f"TEMPLATE (selected): {template_id} {template_slug}")
    print(f"TEMPLATE PATH: {template_path}")
    print()

    print(f"JD TERMS (gate): {', '.join(jd_terms) if jd_terms else '(none detected)'}")
    print()

    print(f"JD TERMS (missing-only gate): {', '.join(missing_terms) if missing_terms else '(none missing)'}")
    print()

    if dropped:
        print(f"NOTE: dropped {dropped} unsafe proposal(s).")
        # show up to 10 drop reasons for debugging
        for d in dropped_notes[:10]:
            b = (d.get("before") or "")
            b = b if len(b) <= 120 else (b[:119] + "…")
            print(f"  - [{d.get('section','?')}] {d.get('reason')}: {b}")
        print()    

    if args.diff:
        print_diff(filtered)
    else:
        if filtered:
            print("Proposed localized edits (READ-ONLY):")
            for p in filtered:
                print(f"{p['id']}. [{p['section']}] {p.get('rationale','')}".rstrip())
        else:
            print("Proposed localized edits (READ-ONLY): none.")
        print()

    # Write proposals file (non-destructive)
    out_dir = app / "resume_refs"
    out_dir.mkdir(parents=True, exist_ok=True)
    out_p = out_dir / "edit-proposals.json"

    payload = {
        "app": str(app),
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "job": {
            "company": jm.get("company"),
            "role_title": jm.get("role_title"),
            "date_found": jm.get("date_found"),
        },
        "template": {
            "template_id": template_id,
            "template_slug": template_slug,
            "template_path": str(template_path),
        },
        "proposals": filtered,
        "notes": "READ-ONLY proposals. These do not modify the resume. Use resume-approve-edits to approve by id."
    }

    if args.no_write:
        print("NOTE: --no-write set; not writing edit-proposals.json")
    else:
        out_p.write_text(json.dumps(payload, indent=2) + "\n")
        print(f"Wrote proposals: {out_p}")

if __name__ == "__main__":
    main()
